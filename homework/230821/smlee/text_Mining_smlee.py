from collections import defaultdict, OrderedDict

text = '''
"AI경쟁으로 ‘합성 데이터’ 부상
지난해 11월 오픈에이아이(OpenAI)가 ‘챗지피티’를 공개한 이후 정보기술업계의 생성 인공지능 개발 경쟁에 불이 붙었다. 구글 바드(Bard), 페이스북 라마(LLaMA), 바이두 어니봇, 네이버 하이퍼클로바엑스(X) 등이 잇따라 출시되며 본격 서비스 경쟁이 시작됐다. 인공지능에 대한 관심과 투자가 확대되는 상황에서 생성 인공지능의 미래가 걸린 ‘합성 데이터(Synthetic Data)’ 문제가 부상하고 있다. 합성데이터는 개인정보, 데이터 편향성 등의 문제를 우회해 고품질의 그림과 문장 등을 생성할 수 있는 대안으로 기대를 모았다. 하지만 생성 인공지능의 결과물을 과도하게 학습할 경우 자칫 근친교배에 가까운 현상이 나타나 인공지능의 붕괴로 이어질 수 있다는 우려가 높아지고 있다.
실제 데이터의 한계와 대안
챗지피티가 웹에서 찾을 수 있는 정보 대부분을 학습했다고 알려진 것처럼, 인공지능 학습은 방대한 데이터를 연료로 하는데 적절한 데이터를 구하는 것은 어렵고 비용이 많이 드는 일이다. 고품질 데이터는 많지 않고 의료정보나 개인정보처럼 접근이 제한되고 규제대상이며, 백인남성 과다 대표 현상처럼 편향성을 지닐 수 있다. 합성 데이터는 원본 데이터의 통계적 특성과 구조를 이용해 만들어낸 원본과 유사한 속성의 ‘인공 데이터’로, 최근엔 인공지능을 활용해 고품질의 합성 데이터 생산이 활발하게 이뤄지고 있다.
금융기관이나 유통기업은 고객들의 행동 예측, 대출 결정, 사기 예방, 시장분석 등의 시뮬레이션을 진행할 때 합성 데이터를 활용한다. ‘엠아이티(MIT) 테크놀로지 리뷰’에 따르면, 나이지리아의 데이터과학자들은 컴퓨터 비전 알고리즘을 학습시키는 과정에서 서양 의복 데이터는 많지만 아프리카 의상을 보여주는 데이터세트가 전혀 없다는 것을 알고, 인공지능을 이용해 아프리카 의상 가상 이미지들을 생성해 훈련시켰다. 이런 합성 데이터는 현실의 데이터와 유사한 구조와 속성을 갖고 있지만, 개인정보와 민감정보를 담고 있지 않은 허구 데이터이기 때문에 이용자 동의가 필요 없고 규제에서 자유롭다. 고품질 데이터를 만들려면 태그와 분류작업(레이블링)에 많은 비용이 들지만, 인공지능은 100분 1에 불과한 비용으로 합성 데이터를 만들어 비슷한 품질을 구현할 수 있다.
지난해 엠아이티 테크놀로지 리뷰는 미래 10대 기술의 하나로 합성 데이터를 선정했고, 시장조사기관 가트너는 “2030년까지 다양한 인공지능 모델에서 진짜 데이터보다 합성 데이터가 더 많아질 것”이라는 보고서를 발표했다. 오픈에이아이의 최고경영자 샘 올트먼은 지난 5월 런던에서 열린 행사에서 “곧 모든 데이터가 합성 데이터가 될 것이라고 확신한다”고 말한 바 있다. 스케일에이아이(ScaleAI), 그레텔에이아이(GretelAI), 신세시스 에이아이(SynthesisAI), 데이터젠(Datagen) 등 합성 데이터 전문 스타트업에 대한 투자와 인수합병도 활발하다.

생성 인공지능의 ‘아킬레스건’
합성 데이터는 실제 데이터의 한계와 편향성 문제를 극복하기 위한 도구로 조명받고 있지만, 인공지능 모델 자체의 붕괴로 이어질 수 있는 중대한 문제를 안고 있다.
지난 2월, 호주 모내시대학의 데이터과학자 제이선 섀도스키는 이를 ‘합스부르크 인공지능’이라고 부르며 “다른 생성 인공지능의 결과물을 지나치게 많이 학습한 시스템이 과장되고 기괴한 특징을 가진 근친교배 돌연변이가 되는 현상”이라고 설명했다. 지난 5월 옥스퍼드대의 일리야 슈마일로프 등의 연구진은 ‘반복의 저주’ 논문에서 “허위나 조작이 포함된 결과물로 인공지능 모델을 학습시키면 시간이 지나면서 기술이 손상되고 저하되어 ‘돌이킬 수 없는 결함’이 발생하고 모델 붕괴로 이어진다”고 경고했다.
정보기술 매체 ‘퓨처리즘’은 지난 2일 “갈수록 더 많은 인공지능 모델이 실제 데이터만이 아니라 다른 생성 인공지능에 의해 합성된 데이터를 학습하는 시대로 접어들었다”고 보도했다. 생성 인공지능이 비용이 저렴하거나 실제 데이터가 충분하지 않다는 등의 이유로 합성 데이터를 사용하기 시작하면 이는 무한한 되먹임 효과로 이어져 인터넷과 인공지능 모델의 품질을 크게 저하시킬 위험이 크다.
‘신뢰할수있는인공지능연구센터’(CATAI) 공동설립자인 개리 마커스 뉴욕대 교수는 “인공지능의 환각 문제는 현재의 방법론으로 해결할 수 없는, 생성 인공지능 모델의 버그 아닌 기능으로 남을 것”이라며 “데이터를 추가해 문제를 해결할 수 있다는 환상이 있지만, 데이터로 문제를 해결할 수 없다”고 지난 16일 ‘파이낸셜 타임스’와의 인터뷰에서 밝혔다.
챗지피티와 같은 생성 인공지능은 사람이 수고롭게 만들어내는 각종 창작물과 데이터를 순식간에 무한히 만들어내며 충격과 경탄을 불러왔다. 그런데 바로 그 ‘합성 데이터’의 무한 되먹임 현상으로 인해 생성 인공지능은 환각과 모델 붕괴의 과제에 직면하게 됐다."
'''.lower().split()

word_count = defaultdict(lambda: 0)
print(f"전체내용: {text}")
print("\n")
for word in text:
    word_count[word] += 1

for i, v in OrderedDict(sorted(word_count.items(), key=lambda t: t[1], reverse=True)).items():
    if v >= 3:
        print(i, v)
